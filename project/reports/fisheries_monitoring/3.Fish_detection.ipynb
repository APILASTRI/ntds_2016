{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fish detection\n",
    "In this notebook we address the problem of detecting and cropping the fishes from the data images. This is a problem of computer vision that has no easy solution. We considered different approaches, being the most relevant ones the following three:\n",
    "- Passing the whole image to a CNN: As shown in the data exploration section, the images contain many different elements being the fishes just a small part of the image. Given the small amount of available training data this strategy gave a very low performance, very close to random classification. Therefore, we discarded this possibility.\n",
    "- Template matching: Most of the classes contain images in which the fishes are in similar positions. Thus, using several templates a number of fishes can be succesfully detected and cropped. However, this approach presents some important problems. Firstly, the test set does not necessarily contain images in which the fishes match any template, yielding the template matching useless. And secondly, in order to detect an acceptable number of fishes a big number of templates should be used for each class, every image should be compared against all the templates of all classes which takes an extremely long time.\n",
    "- Slidding window: The main idea is to sweep every image with a slidding window of different sizes and finding the probability for each frame of containinng a fish. The frame with the highest probability is then selected and stored.\n",
    "\n",
    "After trying all these possibilities we concluded that the slidding window offered the best trade-off between performance and computation time, so we took this option. In order to implement this system a classifier is necessary, which means that we need training data. However, the training data provided by the kaggle competition is not adequate because it consists of whole images, not of frames or cropped fishes. For this reason we have need to modify this images in order to obtain cropped fishes. \n",
    "\n",
    "To do this we firstly cut some images manually (20 of each class) and trained the slidding window with two classes, \"fish\" and \"no fish\". Then, we ran it on several of the original images and selected manually the ones that were well detected and feeded them to the \"fish\" class. The wrongly detected frames were given to the \"no fish\" class. We repeated this process iteratively many times, the performance being increased little by little every time. Nevertheless, this process was very time consuming, so to speed it up we used template matching. In the classes \"LAG\", \"SHARK\" and \"DOL\" the template matching was very effective. After a long process we obtained about 2500 images of cropped fishes and 8500 frames of \"no fish\". Some of the pieces of code used in this process, like the template matching, are not included in this or any other notebook since we were used as a mean to obtain the fish detector here presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from SimpleCV import *\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "from skimage.transform import pyramid_gaussian\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import sum as ndi_sum\n",
    "from subprocess import check_output\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the libraries we declare the functions that we need for the fish detection. As introduced above we need a slidding window and a classificator to determine the probability of a frame containing a fish.\n",
    "\n",
    "For the slidding window we will sweep the image with a square capturing (not storing) the frames. Once the image is completely swept, it is resized smaller and swept again. The effect of this is that the image is swept with squares of different sizes. To do this we use the functions pyramid and sliding window.\n",
    "\n",
    "For the classificator we extract the HOG features, which give a characterization of the image, and we give them to a SVM. The SVM has the advantage that is very fast, so given the very big amount of images to classify and the many frames that are extracted per image it is the best option. \n",
    "\n",
    "Given the poor results obtained when using a single SVM distinguishing between \"fish\" and \"no fish\", we adopt the following strategy for classification. We build seven SVM with two classes each, \"no fish\", and one per class of fish (ALB, BET, DOL, LAG, SHARK, YFT), and one SVM for all of these classes convined. Then we select the frame that gives the highest probability for each class of fish, producing in this way six cropped images from the original image. Then, using the SVM of \"fish\" vs \"no fish\" we select out of the six selected frames the one that is the most similar to a fish. The code doing this will be seen later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################## Functions definition ###################################\n",
    "#These functions are inspired from http://www.pyimagesearch.com/\n",
    "\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    " \n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width=w)\n",
    " \n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    " \n",
    "        # yield the next image in the pyramid\n",
    "        yield image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in xrange(0, image.shape[0], stepSize):\n",
    "        for x in xrange(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "\n",
    "# lenet 5\n",
    "def findHOGFeatures(self, n_divs=3, n_bins=6):\n",
    "    \"\"\"\n",
    "    **SUMMARY**\n",
    "    Get HOG(Histogram of Oriented Gradients) features from the image.\n",
    "\n",
    "\n",
    "    **PARAMETERS**\n",
    "    * *n_divs* - the number of divisions(cells).\n",
    "    * *n_divs* - the number of orientation bins.\n",
    "\n",
    "    **RETURNS**\n",
    "    Returns the HOG vector in a numpy array\n",
    "\n",
    "    \"\"\"\n",
    "    n_HOG = n_divs * n_divs * n_bins  # Size of HOG vector\n",
    "\n",
    "    HOG = np.zeros((n_HOG, 1))  # Initialize output HOG vector\n",
    "\n",
    "    # Apply sobel on image to find x and y orientations of the image\n",
    "    Icv = self.getNumpyCv2()\n",
    "    Ix = cv2.Sobel(Icv, ddepth=cv.CV_32F, dx=1, dy=0, ksize=3)\n",
    "    Iy = cv2.Sobel(Icv, ddepth=cv.CV_32F, dx=0, dy=1, ksize=3)\n",
    "\n",
    "    Ix = Ix.transpose(1, 0, 2)\n",
    "    Iy = Iy.transpose(1, 0, 2)\n",
    "    cellx = self.width / n_divs  # width of each cell(division)\n",
    "    celly = self.height / n_divs  # height of each cell(division)\n",
    "\n",
    "    # Area of image\n",
    "    img_area = self.height * self.width\n",
    "\n",
    "    #Range of each bin\n",
    "    BIN_RANGE = (2 * pi) / n_bins\n",
    "\n",
    "    angles = np.arctan2(Iy, Ix)\n",
    "    magnit = ((Ix ** 2) + (Iy ** 2)) ** 0.5\n",
    "\n",
    "    height, width = self.height, self.width\n",
    "    bins = (angles[...,0] % (2 * pi) / BIN_RANGE).astype(int)\n",
    "    x, y = np.mgrid[:width, :height]\n",
    "    x = x * n_divs // width\n",
    "    y = y * n_divs // height\n",
    "    labels = (x * n_divs + y) * n_bins + bins\n",
    "    index = np.arange(n_HOG)\n",
    "    HOG = ndi_sum(magnit[..., 0], labels, index)\n",
    "\n",
    "    return HOG / (height*width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last definitions to be made are the constant parameters used along this notebook. Due to the unbalance amount of data, we oversample the classes (BET, DOL, LAG and SHARK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define some values and constants\n",
    "fish_classes = ['ALB','BET','LAG','DOL','SHARK','YFT','NoF']\n",
    "fish_classes_test = ['Fish','NoFish']\n",
    "number_classes = len(fish_classes)\n",
    "main_path_train = '../train_cut_oversample'\n",
    "main_path_test = '../test'\n",
    "extension = \"*.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate the HOG arrays for all seven classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4640, 54)\n",
      "(1316, 54)\n",
      "(693, 54)\n",
      "(660, 54)\n",
      "(609, 54)\n",
      "(585, 54)\n",
      "(777, 54)\n",
      "(8460, 54)\n"
     ]
    }
   ],
   "source": [
    "############################## Get HOG of fish and No-fish cases ###################################\n",
    "\n",
    "#One array per classifier\n",
    "HOG = []\n",
    "HOG_n = []\n",
    "HOG_ALB = []\n",
    "HOG_BET = []\n",
    "HOG_DOL = []\n",
    "HOG_LAG = []\n",
    "HOG_SHARK = []\n",
    "HOG_YFT = []\n",
    "\n",
    "\n",
    "#Construct arrays\n",
    "for classes in fish_classes:\n",
    "    #Acces the files\n",
    "    path_class = os.path.join(main_path_train,classes)\n",
    "    directory = os.path.join(path_class, extension)\n",
    "    files = glob.glob(directory)  \n",
    "    for file in files:       \n",
    "        new_img = cv2.imread(file)\n",
    "        H = findHOGFeatures(Image(new_img))\n",
    "        if classes != 'NoF':\n",
    "            HOG.append(H)\n",
    "            if classes == 'ALB':\n",
    "                HOG_ALB.append(H)\n",
    "            if classes == 'BET':\n",
    "                HOG_BET.append(H)\n",
    "            if classes == 'DOL':\n",
    "                HOG_DOL.append(H)\n",
    "            if classes == 'LAG':\n",
    "                HOG_LAG.append(H)\n",
    "            if classes == 'SHARK':\n",
    "                HOG_SHARK.append(H)\n",
    "            if classes == 'YFT':\n",
    "                HOG_YFT.append(H)\n",
    "        else:\n",
    "            HOG_n.append(H)\n",
    "            \n",
    "HOG = np.array(HOG)\n",
    "HOG_ALB = np.array(HOG_ALB)\n",
    "HOG_BET = np.array(HOG_BET)\n",
    "HOG_DOL = np.array(HOG_DOL)\n",
    "HOG_LAG = np.array(HOG_LAG)\n",
    "HOG_SHARK = np.array(HOG_SHARK)\n",
    "HOG_YFT = np.array(HOG_YFT)\n",
    "HOG_n = np.array(HOG_n)\n",
    "\n",
    "#Print shapes of the arrays\n",
    "print HOG.shape\n",
    "print HOG_ALB.shape\n",
    "print HOG_BET.shape\n",
    "print HOG_DOL.shape\n",
    "print HOG_LAG.shape\n",
    "print HOG_SHARK.shape\n",
    "print HOG_YFT.shape\n",
    "print HOG_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################## Build and train the classifiers ###################################\n",
    "\n",
    "#SVM with all classes against No Fish\n",
    "X = np.concatenate((HOG, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_all = SVC(probability=True)\n",
    "clf_all.fit(X, y) \n",
    "\n",
    "#SVM: ALB vs No Fish\n",
    "X = np.concatenate((HOG_ALB, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_ALB.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_ALB = SVC(probability=True)\n",
    "clf_ALB.fit(X,y)\n",
    "\n",
    "#SVM: BET vs No Fish\n",
    "X = np.concatenate((HOG_BET, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_BET.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_BET = SVC(probability=True)\n",
    "clf_BET.fit(X,y)\n",
    "\n",
    "#SVM: DOL vs No Fish\n",
    "X = np.concatenate((HOG_DOL, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_DOL.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_DOL = SVC(probability=True)\n",
    "clf_DOL.fit(X,y)\n",
    "\n",
    "#SVM: LAG vs No Fish\n",
    "X = np.concatenate((HOG_LAG, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_LAG.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_LAG = SVC(probability=True)\n",
    "clf_LAG.fit(X,y)\n",
    "\n",
    "#SVM: SHARK vs No Fish\n",
    "X = np.concatenate((HOG_SHARK, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_SHARK.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_SHARK = SVC(probability=True)\n",
    "clf_SHARK.fit(X,y)\n",
    "\n",
    "#SVM: YFT vs No Fish\n",
    "X = np.concatenate((HOG_YFT, HOG_n),axis = 0)\n",
    "class_one = np.ones(HOG_YFT.shape[0])\n",
    "class_zero = np.zeros(HOG_n.shape[0])\n",
    "y = np.concatenate((class_one, class_zero), axis=0)\n",
    "\n",
    "clf_YFT = SVC(probability=True)\n",
    "clf_YFT.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already explained, the output of the following code are six frames per image, stored in a folder called \"buffer\". The fact that we have the test data organized in classes does not influence neither de detection nor the classification, it just helps us to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################### Apply 6 classifiers (buffer) ##################################\n",
    "\n",
    "\n",
    "(winW, winH) = (100, 100)\n",
    "\n",
    "#Apply classifier on test\n",
    "directory = os.path.join(main_path_test, extension)\n",
    "files = glob.glob(directory)\n",
    "extension = \"*.jpg\"\n",
    "for classes in fish_classes:\n",
    "    path_class = os.path.join(main_path_test,classes)\n",
    "    \n",
    "    directory = os.path.join(path_class, extension)\n",
    "    files = glob.glob(directory)\n",
    "\n",
    "    for file in files:\n",
    "        image = cv2.imread(file)\n",
    "        prob_ALB = 0\n",
    "        prob_BET = 0\n",
    "        prob_DOL = 0\n",
    "        prob_LAG = 0\n",
    "        prob_SHARK = 0\n",
    "        prob_YFT = 0\n",
    "        \n",
    "        # loop over the image pyramid\n",
    "        for resized in pyramid(image, scale=1.5):\n",
    "            # loop over the sliding window for each layer of the pyramid\n",
    "            for (x, y, window) in sliding_window(resized, stepSize=64, windowSize=(winW, winH)):\n",
    "                # if the window does not meet our desired window size, ignore it\n",
    "                if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                    continue\n",
    "                H = findHOGFeatures(Image(window))\n",
    "                \n",
    "                #Predict probability for each class\n",
    "                p_ALB = clf_ALB.predict_proba([H])\n",
    "                p_BET = clf_BET.predict_proba([H])\n",
    "                p_DOL = clf_DOL.predict_proba([H])\n",
    "                p_LAG = clf_LAG.predict_proba([H])\n",
    "                p_SHARK = clf_SHARK.predict_proba([H])\n",
    "                p_YFT = clf_YFT.predict_proba([H])\n",
    "                 \n",
    "                #Store frame with the highest probability per class\n",
    "                if prob_ALB < p_ALB[0,1]:\n",
    "                    prob_ALB = p_ALB[0,1]\n",
    "                    wind_ALB = window\n",
    "                if prob_BET< p_BET[0,1]:\n",
    "                    prob_BET = p_BET[0,1]\n",
    "                    wind_BET = window\n",
    "                if prob_DOL<p_DOL[0,1]:\n",
    "                    prob_DOL = p_DOL[0,1]\n",
    "                    wind_DOL = window\n",
    "                if prob_LAG<p_LAG[0,1]:\n",
    "                    prob_LAG = p_LAG[0,1]\n",
    "                    wind_LAG = window\n",
    "                if prob_SHARK<p_SHARK[0,1]:\n",
    "                    prob_SHARK = p_SHARK[0,1]\n",
    "                    wind_SHARK = window\n",
    "                if prob_YFT<p_YFT[0,1]:\n",
    "                    prob_YFT = p_YFT[0,1]\n",
    "                    wind_YFT = window\n",
    "                                           \n",
    "        j = 0\n",
    "        for wind in [wind_ALB,wind_BET,wind_DOL,wind_LAG,wind_SHARK,wind_YFT] :   \n",
    "            f = str(os.path.basename(file))\n",
    "            cv2.imwrite(\"buffer/\"+str(classes)+\"/\"+f[:-4]+\"_\"+str(j)+\"0.jpg\", wind)\n",
    "            j = j+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the SVM \"Fish\" vs \"No Fish\" in order to select the image which is the most similar to a fish and we store in a folder called \"fish_detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################### Apply 1 classifier (fish_detected) ##################################\n",
    "\n",
    "#from PIL import Image\n",
    "path = \"buffer/\"\n",
    "extension2 = \"*_00.jpg\"\n",
    "nam = \"\"\n",
    "directory = os.path.join(path, extension)\n",
    "files = glob.glob(directory)\n",
    "\n",
    "for classes in fish_classes:\n",
    "    #Access folders\n",
    "    path_class = os.path.join(path,classes)    \n",
    "    directory = os.path.join(path_class, extension2)\n",
    "    files = glob.glob(directory)\n",
    "    for file in files:\n",
    "        prob_fish = 0\n",
    "        f = str(os.path.basename(file))\n",
    "        #Access files\n",
    "        ext = f[:-6]+\"*.jpg\"\n",
    "        direct = os.path.join(path_class, ext)\n",
    "        for name in glob.glob(direct):\n",
    "            #Open image\n",
    "            img = cv2.imread(name)\n",
    "            if img.shape == (100,100,3):        #Check that the image generated by the slidding window has the right size\n",
    "                #Predict probabilities\n",
    "                H = findHOGFeatures(Image(img))\n",
    "                aux = clf_all.predict_proba([H])\n",
    "                #Store highest probability frame\n",
    "                if prob_fish < aux[0,1]:\n",
    "                    prob_fish = aux[0,1]                   \n",
    "                    img = np.reshape(img, (ROWS_RESIZE, COLS_RESIZE,3))\n",
    "                    img_save = img\n",
    "                    nam = name              \n",
    "        #Save frame\n",
    "        cv2.imwrite(\"fish_detected/\"+str(classes)+\"/\"+str(os.path.basename(nam)), img_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This classifier has been applied on a test set. To determine if a fish is correctly detected we need to check manually all the images that have been stored in \"fish_detected\". The results are shown in the following table.\n",
    "\n",
    "| Class | ALB   | BET   | DOL   | LAG   |  SHARK  |  YFT  |\n",
    "|------ |------ |------ |------ |------ |-------- |------ |\n",
    "| Test  | 115   | 95    | 76    | 51    |   81    | 107   |\n",
    "| Detect| 17    | 13    | 28    | 18    | 28      | 32    |\n",
    "| %     | 14.78%| 13.68%| 36.84%| 35.25%| 34.57%  | 29.91%|\n",
    "\n",
    "\n",
    "| TOTAL SAMPLES | 525   | \n",
    "|-------------- |------ |\n",
    "| TOTAL DETECTED| 136  | \n",
    "| TOTAL %       | 25.90%|\n",
    "\n",
    "Given the complexity of the prbblem and the difficult nature of the images, we consider a detection accuracy of 25.9% as a very good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
