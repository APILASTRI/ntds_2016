{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploitation\n",
    "\n",
    "During this data exploitation, we want to find a pattern between the thumbnail of a Youtube video and the number of views of this video. In order to realize this image processing algorithm, we used a Convolutional Neural Network with one convolution, one ReLU activation and one fully connected layer:\n",
    "$$\n",
    "y=\\textrm{softmax}(ReLU(x\\ast W_1+b_1)W_2+b_2)\n",
    "$$\n",
    "\n",
    "**I/ Preparation of the data for the CNN algorithm ** \n",
    "\n",
    "**I.1/ ** Get the images in the right dimension and format.\n",
    "\n",
    "**I.2/ ** Create the train data from the images \n",
    "\n",
    "**I.3/ ** Create the test data, images picked in the train data randomly\n",
    "\n",
    "**I.4/ ** Create the labels (equivalent to the classes) of the train data and of the test data\n",
    "\n",
    "**I.5/ ** Suppress in the train data the images used to create the test data.\n",
    "\n",
    "**II/ Model 1 : random video**\n",
    "\n",
    "The video are taken without a specify thematic, but with random key words in the file CREATE_VIDEO_DATABASE.\n",
    "\n",
    "**II.1/ ** Definition of the computational graph\n",
    "\n",
    "**II.2/ ** Run the computational graph\n",
    "\n",
    "**III/ Model 2 : video with a same thematic**\n",
    "\n",
    "The video are taken with a specify thematic (main subject is \"cars\"). \n",
    "\n",
    "**III.1/ ** Definition of the computational graph\n",
    "\n",
    "**III.2/ ** Run the computational graph\n",
    "\n",
    "**IV/ Exploitation of the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import collections\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "folder = os.path.join('videos_data_CNN2', 'youtube_fame') # model 1 :videos_data_CNN1/youtube_fame -- model 2 : videos_data_CNN2/youtube_fame\n",
    "\n",
    "imag = pd.read_sql('imag', 'sqlite:///' + os.path.join(folder, 'imag.sqlite')) # model 1 : imag1000 -- model 2 : imag\n",
    "data_video = pd.read_sql('videos', 'sqlite:///' + os.path.join(folder, 'videos.sqlite'))\n",
    "\n",
    "print(len(imag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I/Preparation of the data for the CNN algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591\n",
      "(90, 120, 3)\n",
      "(90, 120, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# I.1/ import image and reshape them, learn the indices from the ones with wrong size, does not reshape them\n",
    "\n",
    "Images=[]\n",
    "print(len(imag['imag']))\n",
    "ind_wrong_size=[]\n",
    "for i in range(len(imag['imag'])):\n",
    "    if i!=0:\n",
    "        images=np.fromstring(imag['imag'][i],dtype=np.float32)\n",
    "        if len(images)==32400:\n",
    "            Images+=[images.reshape([90,120,3])]\n",
    "        else:\n",
    "            ind_wrong_size+=[i]\n",
    "            \n",
    "print(Images[10].shape)\n",
    "print(Images[100].shape)\n",
    "print(len(ind_wrong_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_orig shape: (590, 90, 120, 3)\n",
      "train_data shape: (590, 10800)\n"
     ]
    }
   ],
   "source": [
    "# I.2/\n",
    "\n",
    "nbr_video = len(Images)\n",
    "test_size = 50\n",
    "height_video = Images[0].shape[0]\n",
    "width_video = Images[0].shape[1]\n",
    "size_video = Images[0].shape[2]\n",
    "\n",
    "# creation of the train data:\n",
    "\n",
    "train_data_orig = np.zeros([nbr_video,height_video,width_video,size_video])\n",
    "for i in range(nbr_video):\n",
    "    train_data_orig[i,:,:,:]=Images[i]\n",
    "print('train_data_orig shape:', train_data_orig.shape)\n",
    "\n",
    "train_data = np.zeros([nbr_video,height_video*width_video])\n",
    "for i in range(nbr_video):\n",
    "    xx = train_data_orig[i,:,:,:]\n",
    "    xx = np.linalg.norm(xx,axis=2)\n",
    "    xx -= np.mean(xx)\n",
    "    xx /= np.linalg.norm(xx)\n",
    "    train_data[i] = np.reshape(xx,[-1])\n",
    "    \n",
    "\n",
    "print('train_data shape:', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices =  [  2  11  30  49  61  69  71  83  92 166 169 170 187 199 218 221 222 244\n",
      " 252 277 278 285 312 331 383 385 394 400 412 417 425 438 448 455 475 478\n",
      " 501 507 511 512 513 534 537 538 566 573 574 582 585 588]\n",
      "test_data_orig shape: (50, 90, 120, 3)\n",
      "test_data shape: (50, 10800)\n"
     ]
    }
   ],
   "source": [
    "# I.3/creation of the test data: random indices array taken from train data generated\n",
    "\n",
    "nb_elem = test_size \n",
    "indices = []  \n",
    "while nb_elem > 0:  \n",
    "    i = random.randint(0, nbr_video -1)  \n",
    "    while i in indices: # in order to not have twice the same indice  \n",
    "        i = random.randint(0, nbr_video -1)  \n",
    "    indices.append(i)  \n",
    "    nb_elem = nb_elem - 1  \n",
    "    \n",
    "indices=np.sort(indices) \n",
    "\n",
    "print('Indices = ',indices)\n",
    "\n",
    "test_data_orig = np.zeros([test_size,height_video,width_video,size_video])\n",
    "for i in range(test_size):\n",
    "    test_data_orig[i,:,:,:] = Images[indices[i]]\n",
    "    \n",
    "print('test_data_orig shape:', test_data_orig.shape)\n",
    "    \n",
    "test_data = np.zeros([test_size,height_video*width_video])\n",
    "for i in range(test_size):\n",
    "    xx = test_data_orig[i,:,:,:]\n",
    "    xx = np.linalg.norm(xx,axis=2)\n",
    "    xx -= np.mean(xx)\n",
    "    xx /= np.linalg.norm(xx)\n",
    "    test_data[i] = np.reshape(xx,[-1])\n",
    "    \n",
    "print('test_data shape:', test_data.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I.4/\n",
    "\n",
    "max_view = int(0);\n",
    "min_view = int(99999999);\n",
    "nbr_labels = 7;\n",
    "\n",
    "# creation of the train labels\n",
    "\n",
    "train_labels = np.zeros([nbr_video,nbr_labels])\n",
    "for i in range(nbr_video):\n",
    "    if i!=ind_wrong_size:\n",
    "        views = int(data_video['viewCount'][i])\n",
    "        \n",
    "        if views > max_view:\n",
    "            max_view = views;\n",
    "        if views < min_view:\n",
    "            min_view = views;\n",
    "\n",
    "        if views < 999:\n",
    "            train_labels[i] = [1,0,0,0,0,0,0]\n",
    "        elif views < 9999:\n",
    "            train_labels[i] = [0,1,0,0,0,0,0]\n",
    "        elif views < 99999:\n",
    "            train_labels[i] = [0,0,1,0,0,0,0]\n",
    "        elif views < 999999:\n",
    "            train_labels[i] = [0,0,0,1,0,0,0]\n",
    "        elif views < 9999999:\n",
    "            train_labels[i] = [0,0,0,0,1,0,0]\n",
    "        elif views < 99999999:\n",
    "            train_labels[i] = [0,0,0,0,0,1,0]\n",
    "        else:\n",
    "            train_labels[i] = [0,0,0,0,0,0,1]\n",
    "        \n",
    "# Creation of the test labels\n",
    "\n",
    "test_labels = np.zeros([len(indices),nbr_labels])\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    test_labels[i]=train_labels[indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 10800)\n",
      "(540, 7)\n"
     ]
    }
   ],
   "source": [
    "# I.5/ suppression in the train data and labels of the video used for the test\n",
    "    \n",
    "for i in range(len(indices)):\n",
    "    train_data = np.delete(train_data, indices[len(indices)-i-1],axis=0)\n",
    "    train_labels = np.delete(train_labels,indices[len(indices)-i-1],axis=0)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** II/ Model 1 **\n",
    "\n",
    "random database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xin= Tensor(\"Placeholder:0\", shape=(100, 10800), dtype=float32) (100, 10800)\n",
      "y_label= Tensor(\"Placeholder_1:0\", shape=(100, 8), dtype=float32) (100, 8)\n",
      "Wcl= (5, 5, 1, 8)\n",
      "x_2d= (100, 120, 90, 1)\n",
      "x= (100, 120, 90, 8)\n",
      "x (100, 120, 90, 8)\n",
      "x (100, 86400)\n",
      "W2= (86400, 8)\n",
      "b2 (8,)\n",
      "y (100, 8)\n",
      "y (100, 8)\n"
     ]
    }
   ],
   "source": [
    "# II.1/\n",
    "\n",
    "tf.reset_default_graph();\n",
    "# Define computational graph (CG)\n",
    "batch_size = len(indices)        # batch size\n",
    "d = train_data.shape[1]  # data dimensionality\n",
    "nc = nbr_labels                  # number of classes\n",
    "tf.reset_default_graph();\n",
    "\n",
    "# CG inputs\n",
    "xin = tf.placeholder(tf.float32,[batch_size,d]); print('xin=',xin,xin.get_shape())\n",
    "y_label = tf.placeholder(tf.float32,[batch_size,nc]); print('y_label=',y_label,y_label.get_shape())\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "K = 5   # size of the patch\n",
    "F = 8  # number of filters\n",
    "\n",
    "Wcl = tf.get_variable(\"Wcl\",shape=[K,K,1,F],initializer=tf.contrib.layers.xavier_initializer()); print('Wcl=',Wcl.get_shape())\n",
    "x_2d = tf.reshape(xin, [-1,120,90,1]);print('x_2d=',x_2d.get_shape())\n",
    "b1 = tf.Variable(tf.zeros([nc]));\n",
    "x = tf.nn.conv2d(x_2d, Wcl, strides=[1, 1, 1, 1], padding='SAME'); print('x=',x.get_shape())\n",
    "x+=b1;\n",
    "# ReLU activation\n",
    "x =  tf.nn.relu(x)\n",
    "print('x',x.get_shape())\n",
    "\n",
    "# Fully Connected layer\n",
    "nfc = 120*90*F\n",
    "x = tf.reshape(x, [batch_size,nfc]); print('x',x.get_shape())\n",
    "W2 = tf.get_variable(\"W2\",shape=[nfc,nc], initializer=tf.contrib.layers.xavier_initializer()); print('W2=',W2.get_shape())\n",
    "b2 = tf.Variable(tf.zeros([nc])); print('b2',b2.get_shape())\n",
    "y = tf.matmul(x,W2);print('y',y.get_shape())\n",
    "y+=b2;\n",
    "# Softmax\n",
    "y = tf.nn.softmax(y)\n",
    "print('y',y.get_shape())\n",
    "\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(tf.maximum(y,1e-15)), 1))\n",
    "total_loss = cross_entropy\n",
    "\n",
    "# Optimization scheme\n",
    "train_step = tf.train.GradientDescentOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-14 17:03:11.859024\n",
      "\n",
      "Iteration i= 0 , train accuracy= 0.12 , loss= 2.0792\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 17:03:15.177353 delta= 0:00:03.318329\n",
      "\n",
      "Iteration i= 1000 , train accuracy= 0.25 , loss= 1.77029\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 17:35:54.516531 delta= 0:32:42.657507\n",
      "\n",
      "Iteration i= 2000 , train accuracy= 0.23 , loss= 1.68974\n",
      "test accuracy= 0.31\n",
      "time= 2017-01-14 18:08:31.306081 delta= 1:05:19.447057\n",
      "\n",
      "Iteration i= 3000 , train accuracy= 0.27 , loss= 1.75065\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 18:43:21.788028 delta= 1:40:09.929004\n",
      "\n",
      "Iteration i= 4000 , train accuracy= 0.24 , loss= 1.6537\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 19:16:20.859350 delta= 2:13:09.000326\n",
      "\n",
      "Iteration i= 5000 , train accuracy= 0.3 , loss= 1.73215\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 19:49:22.448067 delta= 2:46:10.589043\n",
      "\n",
      "Iteration i= 6000 , train accuracy= 0.25 , loss= 1.72493\n",
      "test accuracy= 0.31\n",
      "time= 2017-01-14 20:22:17.600808 delta= 3:19:05.741784\n",
      "\n",
      "Iteration i= 7000 , train accuracy= 0.29 , loss= 1.80252\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 20:55:37.220519 delta= 3:52:25.361495\n",
      "\n",
      "Iteration i= 8000 , train accuracy= 0.25 , loss= 1.80218\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 21:29:41.628636 delta= 4:26:29.769612\n",
      "\n",
      "Iteration i= 9000 , train accuracy= 0.31 , loss= 1.77169\n",
      "test accuracy= 0.26\n",
      "time= 2017-01-14 22:03:29.904100 delta= 5:00:18.045076\n",
      "\n",
      "Iteration i= 10000 , train accuracy= 0.18 , loss= 1.64676\n",
      "test accuracy= 0.31\n",
      "time= 2017-01-14 22:36:43.639128 delta= 5:33:31.780104\n"
     ]
    }
   ],
   "source": [
    "# II.2/\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "print(today)\n",
    "# Run Computational Graph\n",
    "n = train_data.shape[0]\n",
    "indices = collections.deque()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(10001):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < batch_size:\n",
    "        indices.extend(np.random.permutation(n)) \n",
    "    idx = [indices.popleft() for i in range(batch_size)]\n",
    "    batch_x, batch_y = train_data[idx,:], train_labels[idx]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    \n",
    "    # Run CG for variable training\n",
    "    _,acc_train,total_loss_o = sess.run([train_step,accuracy,total_loss], feed_dict={xin: batch_x, y_label: batch_y})\n",
    "    \n",
    "    # Run CG for test set\n",
    "    if not i%1000:\n",
    "        print('\\nIteration i=',i,', train accuracy=',acc_train,', loss=',total_loss_o)\n",
    "        acc_test = sess.run(accuracy, feed_dict={xin: test_data, y_label: test_labels})\n",
    "        print('test accuracy=',acc_test)\n",
    "        today2 = datetime.datetime.now()\n",
    "        print('time=',today2,'delta=',today2-today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**III/ Model 2**\n",
    "\n",
    "test with specify thematic : videos chosen around the subject 'car'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xin= Tensor(\"Placeholder:0\", shape=(50, 10800), dtype=float32) (50, 10800)\n",
      "y_label= Tensor(\"Placeholder_1:0\", shape=(50, 7), dtype=float32) (50, 7)\n",
      "Wcl= (5, 5, 1, 7)\n",
      "x_2d= (50, 120, 90, 1)\n",
      "x= (50, 120, 90, 7)\n",
      "x (50, 120, 90, 7)\n",
      "x (50, 75600)\n",
      "W2= (75600, 7)\n",
      "b2 (7,)\n",
      "y (50, 7)\n",
      "y (50, 7)\n"
     ]
    }
   ],
   "source": [
    "# III.1/\n",
    "\n",
    "tf.reset_default_graph();\n",
    "# Define computational graph (CG)\n",
    "batch_size = len(indices)        # batch size\n",
    "d = train_data.shape[1]  # data dimensionality\n",
    "nc = nbr_labels                  # number of classes\n",
    "tf.reset_default_graph();\n",
    "\n",
    "# CG inputs\n",
    "xin = tf.placeholder(tf.float32,[batch_size,d]); print('xin=',xin,xin.get_shape())\n",
    "y_label = tf.placeholder(tf.float32,[batch_size,nc]); print('y_label=',y_label,y_label.get_shape())\n",
    "\n",
    "\n",
    "# Convolutional layer\n",
    "K = 5   # size of the patch\n",
    "F = 7  # number of filters\n",
    "\n",
    "Wcl = tf.get_variable(\"Wcl\",shape=[K,K,1,F],initializer=tf.contrib.layers.xavier_initializer()); print('Wcl=',Wcl.get_shape())\n",
    "x_2d = tf.reshape(xin, [-1,120,90,1]);print('x_2d=',x_2d.get_shape())\n",
    "b1 = tf.Variable(tf.zeros([nc]));\n",
    "x = tf.nn.conv2d(x_2d, Wcl, strides=[1, 1, 1, 1], padding='SAME'); print('x=',x.get_shape())\n",
    "x+=b1;\n",
    "# ReLU activation\n",
    "x =  tf.nn.relu(x)\n",
    "print('x',x.get_shape())\n",
    "\n",
    "# Fully Connected layer\n",
    "nfc = 120*90*F\n",
    "x = tf.reshape(x, [batch_size,nfc]); print('x',x.get_shape())\n",
    "W2 = tf.get_variable(\"W2\",shape=[nfc,nc], initializer=tf.contrib.layers.xavier_initializer()); print('W2=',W2.get_shape())\n",
    "b2 = tf.Variable(tf.zeros([nc])); print('b2',b2.get_shape())\n",
    "y = tf.matmul(x,W2);print('y',y.get_shape())\n",
    "y+=b2;\n",
    "# Softmax\n",
    "y = tf.nn.softmax(y)\n",
    "print('y',y.get_shape())\n",
    "\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(tf.maximum(y,1e-15)), 1))\n",
    "total_loss = cross_entropy\n",
    "\n",
    "# Optimization scheme\n",
    "train_step = tf.train.GradientDescentOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-15 12:58:40.570765\n",
      "\n",
      "Iteration i= 0 , train accuracy= 0.16 , loss= 1.94502\n",
      "test accuracy= 0.16\n",
      "time= 2017-01-15 12:58:43.131012 delta= 0:00:02.560247\n",
      "\n",
      "Iteration i= 1000 , train accuracy= 0.34 , loss= 1.51785\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 13:16:11.622294 delta= 0:17:31.051529\n",
      "\n",
      "Iteration i= 2000 , train accuracy= 0.4 , loss= 1.46028\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 13:34:25.191300 delta= 0:35:44.620535\n",
      "\n",
      "Iteration i= 3000 , train accuracy= 0.32 , loss= 1.60333\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 13:53:12.516469 delta= 0:54:31.945704\n",
      "\n",
      "Iteration i= 4000 , train accuracy= 0.28 , loss= 1.56005\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 14:11:44.518389 delta= 1:13:03.947624\n",
      "\n",
      "Iteration i= 5000 , train accuracy= 0.22 , loss= 1.57455\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 14:29:58.078347 delta= 1:31:17.507582\n",
      "\n",
      "Iteration i= 6000 , train accuracy= 0.48 , loss= 1.4669\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 14:49:28.284865 delta= 1:50:47.714100\n",
      "\n",
      "Iteration i= 7000 , train accuracy= 0.32 , loss= 1.58102\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 15:08:13.413293 delta= 2:09:32.842528\n",
      "\n",
      "Iteration i= 8000 , train accuracy= 0.4 , loss= 1.53522\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 15:26:42.071823 delta= 2:28:01.501058\n",
      "\n",
      "Iteration i= 9000 , train accuracy= 0.3 , loss= 1.48806\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 15:46:18.164495 delta= 2:47:37.593730\n",
      "\n",
      "Iteration i= 10000 , train accuracy= 0.34 , loss= 1.64062\n",
      "test accuracy= 0.38\n",
      "time= 2017-01-15 16:05:24.336915 delta= 3:06:43.766150\n"
     ]
    }
   ],
   "source": [
    "# III.2/\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "print(today)\n",
    "# Run Computational Graph\n",
    "n = train_data.shape[0]\n",
    "indices = collections.deque()\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(10001):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < batch_size:\n",
    "        indices.extend(np.random.permutation(n)) \n",
    "    idx = [indices.popleft() for i in range(batch_size)]\n",
    "    batch_x, batch_y = train_data[idx,:], train_labels[idx]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    \n",
    "    # Run CG for variable training\n",
    "    _,acc_train,total_loss_o = sess.run([train_step,accuracy,total_loss], feed_dict={xin: batch_x, y_label: batch_y})\n",
    "    \n",
    "    # Run CG for test set\n",
    "    if not i%1000:\n",
    "        print('\\nIteration i=',i,', train accuracy=',acc_train,', loss=',total_loss_o)\n",
    "        acc_test = sess.run(accuracy, feed_dict={xin: test_data, y_label: test_labels})\n",
    "        print('test accuracy=',acc_test)\n",
    "        today2 = datetime.datetime.now()\n",
    "        print('time=',today2,'delta=',today2-today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** IV/ Exploitation of the results**\n",
    "\n",
    "We can see that the train and test accuracies of the two models  stay low : 0.18 for the train and 0.31 for the test for model 1 and 0.34 for the train and 0.38 for the test for model 2. It is explained by the fact that the thumbnail of a youtube video is completely random and depends of the choice of the youtuber. However we can see that for model 2, where the videos were chosen based on a thematic (\"cars\"), the accuracy of both train and test is higher than for the random model 1. \n",
    "\n",
    "The low accuracy of the train can be explained by the fact that the dataset is too small (around 1000 images for model 1, around 600 for model 2) or that the CNN does not go deep enough. We can also observe that the train accuracy is changing a lot and is not stabilizing during the session (the number of iteration could be increased), whereas the test accuracy does not change after 1000 iterations.  \n",
    "\n",
    "A possibility to include the numbers of suscribers of a channel in the CNN was to normalize the number of view per number of subcribers in order to increase the accuracy of the train.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
