{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('The Station {}'.format(station_id)+' has {} docks in total.'.format(station.loc[station_id,'install_dockcount']))\n",
    "\n",
    "#Station by station\n",
    "extract = trip.loc[(trip.from_station_id==station_id) | (trip.to_station_id==station_id),:]\n",
    "def incrementation(row):\n",
    "    if (row['from_station_id']==station_id)&(row['to_station_id']==station_id):\n",
    "        return int(0)\n",
    "    if (row['from_station_id']==station_id):\n",
    "        return int(-1)\n",
    "    if (row['to_station_id']==station_id):\n",
    "        return int(1)\n",
    "extract['incrementation'] = trip.apply(incrementation, axis=1)\n",
    "extract = extract.set_index('trip_id')\n",
    "\n",
    "#Start and Stop\n",
    "temp1 = extract.loc[(extract.incrementation==0),['starttime','stoptime','bikeid','to_station_id','incrementation']]\n",
    "instanteanous_variation = pd.DataFrame(columns=['trip_id','time', 'bikeid', 'destination_id', 'incrementation'])\n",
    "for i in range(temp1.shape[0]):\n",
    "    #-1\n",
    "    serie1 = dict(trip_id=temp1.index[i],bikeid=temp1.bikeid.values[i],destination_id=temp1.to_station_id.values[i])\n",
    "    serie1['incrementation'] = -1\n",
    "    serie1['time'] = temp1.starttime.values[i]\n",
    "    \n",
    "    #+1\n",
    "    serie2 = dict(trip_id=temp1.index[i],bikeid=temp1.bikeid.values[i],destination_id=temp1.to_station_id.values[i])\n",
    "    serie2['incrementation'] = 1\n",
    "    serie2['time'] = temp1.stoptime.values[i]\n",
    "    \n",
    "    instanteanous_variation = instanteanous_variation.append(serie1, ignore_index=True)\n",
    "    instanteanous_variation = instanteanous_variation.append(serie2, ignore_index=True)\n",
    "instanteanous_variation = instanteanous_variation.set_index('trip_id')\n",
    "instanteanous_variation.index = instanteanous_variation.index.astype(int) \n",
    "\n",
    "#Stop\n",
    "temp2 = extract.loc[(extract.incrementation==1.0),['stoptime','bikeid','from_station_id','incrementation']]\n",
    "temp2.columns=['time','bikeid','destination_id','incrementation']\n",
    "instanteanous_variation=instanteanous_variation.append(temp2)\n",
    "\n",
    "#Start\n",
    "temp3 = extract.loc[(extract.incrementation==-1.0),['starttime','bikeid','to_station_id','incrementation']]\n",
    "temp3.columns=['time','bikeid','destination_id','incrementation']\n",
    "instanteanous_variation=instanteanous_variation.append(temp3)\n",
    "\n",
    "#Sort by time before doing cumulative\n",
    "instanteanous_variation.time = pd.to_datetime(instanteanous_variation.time)\n",
    "instanteanous_variation = instanteanous_variation.sort_values('time')\n",
    "\n",
    "#Computation of the total cumulative variation\n",
    "instanteanous_variation['total_variation'] = instanteanous_variation['incrementation'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_start = date(2014,10,13)\n",
    "date_end = date(2016,8,31)\n",
    "dates = [date_start + timedelta(days=x) for x in range((date_end-date_start).days + 1)]\n",
    "\n",
    "daily = []\n",
    "for d in dates:\n",
    "    temp = instanteanous_variation.loc[(instanteanous_variation.time.dt.date==d),['incrementation']].cumsum().values\n",
    "    daily = np.append(daily,temp) \n",
    "instanteanous_variation['daily_variation'] = pd.Series(daily, index=instanteanous_variation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Resample of instanteanous_variation towards regular time step #####\n",
    "\n",
    "sampled_variation = instanteanous_variation.set_index('time').incrementation.groupby(pd.TimeGrouper(freq='15Min')).sum() #every 15Mins\n",
    "sampled_variation = pd.DataFrame(sampled_variation, columns=['incrementation']) #to dataframe\n",
    "sampled_variation = sampled_variation.fillna(value=0) #transform NaN to 0\n",
    "sampled_variation['date'] = sampled_variation.index.date #faster access to date in the following\n",
    "\n",
    "#From incrementation to daily_variation\n",
    "daily = []\n",
    "for d in dates:\n",
    "    temp = sampled_variation.loc[(sampled_variation.date==d),['incrementation']].cumsum().values\n",
    "    daily = np.append(daily,temp) \n",
    "sampled_variation['incrementation'] = pd.Series(daily, index=sampled_variation.index)\n",
    "sampled_variation.columns = ['daily_variation','date']\n",
    "\n",
    "#Removal of first and last day to have full periods of 24h (96 by day)\n",
    "sampled_variation=sampled_variation.loc[(sampled_variation.date!=date_start)&(sampled_variation.date!=date_end),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Concatenate dataframes to regress on later ####\n",
    "columns_weather = ['Events','Mean_Temperature_F','Precipitation_In '] #weather data we will use for the regression\n",
    "repeat_weather = pd.concat([weather.loc[(weather.index.date!=date_start)&(weather.index.date!=date_end),columns_weather]]*96).sort_index(axis=0)# repeated 96 times every day\n",
    "repeat_weather.index=sampled_variation.index #same index to ease concatenation\n",
    "\n",
    "data_to_regress = pd.concat([repeat_weather,sampled_variation],axis=1) #original data to regress on (need then to be numerized)\n",
    "\n",
    "###### Adding a few useful features ######\n",
    "data_to_regress['date'] = data_to_regress.index.month\n",
    "data_to_regress['weekday'] = data_to_regress.index.dayofweek\n",
    "data_to_regress['hour'] = data_to_regress.index.hour + data_to_regress.index.minute/60\n",
    "data_to_regress.columns = ['Events','Mean_Temperature_F','Precipitation_In ','daily_variation','month','weekday','hour']\n",
    "\n",
    "###### Numerizing Events #####\n",
    "data_to_regress.Events = data_to_regress.Events.fillna(value=0)\n",
    "to_one = ['Fog']\n",
    "for k, st in enumerate(to_one):\n",
    "    data_to_regress.loc[(data_to_regress.Events == st),['Events']]=1\n",
    "to_two = ['Rain','Fog , Rain','Fog-Rain', 'Rain-Thunderstorm','Rain , Thunderstorm']\n",
    "for k, st in enumerate(to_two):\n",
    "    data_to_regress.loc[(data_to_regress.Events == st),['Events']]=2\n",
    "to_three = ['Snow','Rain-Snow','Rain , Snow']\n",
    "for k, st in enumerate(to_three):\n",
    "    data_to_regress.loc[(data_to_regress.Events == st),['Events']]=3\n",
    "\n",
    "###### More cleaning ^^ #####\n",
    "data_to_regress = data_to_regress.dropna(axis=0)\n",
    "#print(data_to_regress.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing\n",
    "display(data_to_regress.head())\n",
    "print('DataFrame shape used for regression: {}'.format(data_to_regress.shape))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
