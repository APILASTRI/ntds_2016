{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Network Tour of Data Science\n",
    "\n",
    "[MichaÃ«l Defferrard](http://deff.ch), *PhD student*, [Pierre Vandergheynst](https://people.epfl.ch/pierre.vandergheynst), *Full Professor*, [EPFL](http://epfl.ch) [LTS2](http://lts2.epfl.ch).\n",
    "\n",
    "# Exercise 5: Graph Signals and Fourier Transform\n",
    "\n",
    "The goal of this exercise is to experiment with the notions of graph signals, graph Fourier transform and smoothness and illustrate these concepts in the light of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Graph\n",
    "\n",
    "**Goal**: compute the combinatorial Laplacian $L$ of a graph formed with $c=2$ clusters.\n",
    "\n",
    "**Step 1**: construct and visualize a fabricated data matrix $X = [x_1, \\ldots, x_n]^t \\in \\mathbb{R}^{n \\times d}$ whose lines are $n$ samples embedded in a $d$-dimensional Euclidean space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 2    # Dimensionality.\n",
    "n = 100  # Number of samples.\n",
    "c = 1    # Number of communities.\n",
    "\n",
    "# Data matrix, structured in communities.\n",
    "X = np.random.uniform(0, 1, (n, d))\n",
    "X += np.linspace(0, 2, c).repeat(n//c)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, squeeze=True)\n",
    "ax.scatter(X[:n//c, 0], X[:n//c, 1], c='b', s=40, linewidths=0, label='class 0');\n",
    "ax.scatter(X[n//c:, 0], X[n//c:, 1], c='r', s=40, linewidths=0, label='class 1');\n",
    "lim1 = X.min() - 0.5\n",
    "lim2 = X.max() + 0.5\n",
    "ax.set_xlim(lim1, lim2)\n",
    "ax.set_ylim(lim1, lim2)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: compute all $n^2$ pairwise euclidean distances $\\operatorname{dist}(i, j) = \\|x_i - x_j\\|_2$.\n",
    "\n",
    "Hint: you may use the function `scipy.spatial.distance.pdist()` and `scipy.spatial.distance.squareform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pairwise distances.\n",
    "dist = scipy.spatial.distance.pdist(X, metric='euclidean')\n",
    "dist = scipy.spatial.distance.squareform(dist)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(dist.flatten(), bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: order the distances and, for each sample, solely keep the $k=10$ closest samples to form a $k$ nearest neighbor ($k$-NN) graph.\n",
    "\n",
    "Hint: you may sort a numpy array with `np.sort() or np.argsort()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10  # Miminum number of edges per node.\n",
    "\n",
    "idx = np.argsort(dist)[:, 1:k+1]\n",
    "dist.sort()\n",
    "dist = dist[:, 1:k+1]\n",
    "assert dist.shape == (n, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: compute the weights using a Gaussian kernel, i.e. $$\\operatorname{weight}(i, j) = \\exp\\left(-\\frac{\\operatorname{dist}(i,j)^2}{\\sigma^2}\\right) = \\exp\\left(-\\frac{\\|x_i - x_j\\|_2^2}{\\sigma^2}\\right).$$\n",
    "\n",
    "Hint: you may use the below definition of $\\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling factor.\n",
    "sigma2 = np.mean(dist[:, -1])**2\n",
    "\n",
    "# Weights with Gaussian kernel.\n",
    "dist = np.exp(- dist**2 / sigma2)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(dist.flatten(), bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: construct and visualize the sparse weight matrix $W_{ij} = \\operatorname{weight}(i, j)$.\n",
    "\n",
    "Hint: you may use the function `scipy.sparse.coo_matrix()` to create a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Weight matrix.\n",
    "I = np.arange(0, n).repeat(k)\n",
    "J = idx.reshape(n*k)\n",
    "V = dist.reshape(n*k)\n",
    "W = scipy.sparse.coo_matrix((V, (I, J)), shape=(n, n))\n",
    "\n",
    "# No self-connections.\n",
    "W.setdiag(0)\n",
    "\n",
    "# Non-directed graph.\n",
    "bigger = W.T > W\n",
    "W = W - W.multiply(bigger) + W.T.multiply(bigger)\n",
    "assert type(W) == scipy.sparse.csr_matrix\n",
    "\n",
    "print('n = |V| = {}, k|V| < |E| = {}'.format(n, W.nnz))\n",
    "plt.spy(W, markersize=2, color='black');\n",
    "\n",
    "import scipy.io\n",
    "import os.path\n",
    "scipy.io.mmwrite(os.path.join('datasets', 'graph_inpainting', 'embedding.mtx'), X)\n",
    "scipy.io.mmwrite(os.path.join('datasets', 'graph_inpainting', 'graph.mtx'), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: compute the combinatorial graph Laplacian $L = D - W$ where $D$ is the diagonal degree matrix $D_{ii} = \\sum_j W_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Degree matrix.\n",
    "D = W.sum(axis=0)\n",
    "D = scipy.sparse.diags(D.A.squeeze(), 0)\n",
    "\n",
    "# Laplacian matrix.\n",
    "L = D - W\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, squeeze=True, figsize=(15, 5))\n",
    "axes[0].spy(L, markersize=2, color='black');\n",
    "axes[1].plot(D.diagonal(), '.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Fourier Basis\n",
    "\n",
    "Compute the eigendecomposition $L=U \\Lambda U^t$ of the Laplacian, where $\\Lambda$ is the diagonal matrix of eigenvalues $\\Lambda_{\\ell\\ell} = \\lambda_\\ell$ and $U = [u_1, \\ldots, u_n]^t$ is the graph Fourier basis.\n",
    "\n",
    "Hint: you may use the function `np.linalg.eigh()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb, U = np.linalg.eigh(L.toarray())\n",
    "\n",
    "#print(lamb)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(lamb, '.-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Visualize the eigenvectors $u_\\ell$ corresponding to the first eight non-zero eigenvalues $\\lambda_\\ell$.\n",
    "2. Can you explain what you observe and relate it to the structure of the graph ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scatter(ax, x):\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=x, s=40, linewidths=0)\n",
    "    ax.set_xlim(lim1, lim2)\n",
    "    ax.set_ylim(lim1, lim2)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    u = U[:, i+1]\n",
    "    scatter(ax, u)\n",
    "    ax.set_title('u_{}'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Graph Signals\n",
    "\n",
    "1. Let $f(u)$ be a positive and non-increasing function of $u$.\n",
    "2. Compute the graph signal $x$ whose graph Fourier transform satisfies $\\hat{x}(\\ell) = f(\\lambda_\\ell)$.\n",
    "3. Visualize the result.\n",
    "4. Can you interpret it ? How does the choice of $f$ influence the result ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1(u, a=2):\n",
    "    y = np.zeros(n)\n",
    "    y[:a] = 1\n",
    "    return y\n",
    "def f2(u):\n",
    "    return f1(u, a=3)\n",
    "def f3(u):\n",
    "    return f1(u, a=n//4)\n",
    "def f4(u):\n",
    "    return f1(u, a=n)\n",
    "\n",
    "def f5(u, m=4):\n",
    "    return np.maximum(1 - m * u / u[-1], 0)\n",
    "def f6(u):\n",
    "    return f5(u, 2)\n",
    "def f7(u):\n",
    "    return f5(u, 1)\n",
    "def f8(u):\n",
    "    return f5(u, 1/2)\n",
    "\n",
    "def f9(u, a=1/2):\n",
    "    return np.exp(-u / a)\n",
    "def f10(u):\n",
    "    return f9(u, a=1)\n",
    "def f11(u):\n",
    "    return f9(u, a=2)\n",
    "def f12(u):\n",
    "    return f9(u, a=4)\n",
    "\n",
    "def plot(F):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for f in F:\n",
    "        plt.plot(lamb, eval(f)(lamb), '.-', label=f)\n",
    "    plt.xlim(0, lamb[-1])\n",
    "    plt.legend()\n",
    "\n",
    "F = ['f{}'.format(i+1) for i in range(12)]\n",
    "plot(F[0:4])\n",
    "plot(F[4:8])\n",
    "plot(F[8:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(15, 9))\n",
    "for f, ax in zip(F, axes.flatten()):\n",
    "    xhat = eval(f)(lamb)\n",
    "    x = U.dot(xhat)  # U @ xhat\n",
    "    #x = U.dot(xhat * U.T[:,2])\n",
    "    scatter(ax, x)\n",
    "    ax.set_title(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
